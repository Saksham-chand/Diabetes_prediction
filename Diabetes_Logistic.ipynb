{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c501cc71",
   "metadata": {},
   "source": [
    "Pandas for data reading and preprocessing\n",
    "\n",
    "Numpy to do array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2512b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2da6ace2",
   "metadata": {},
   "source": [
    "Y_hat --> predicted value\n",
    "\n",
    "X --> Input Variable\n",
    "\n",
    "w --> weight\n",
    "\n",
    "b --> bias\n",
    "\n",
    "Gradient Descent:\n",
    "\n",
    "Gradient Descent is an optimization algorithm used for minimizing the loss function in various machine learning algorithms. It is used for updating the parameters of the learning model.\n",
    "\n",
    "w = w - α*dw\n",
    "\n",
    "b = b - α*db\n",
    "\n",
    "Learning Rate:\n",
    "\n",
    "Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b76e0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression():\n",
    "\n",
    "\n",
    "  # declaring learning rate & number of iterations (Hyperparametes)\n",
    "    def __init__(self, learning_rate, no_of_iterations):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.no_of_iterations = no_of_iterations\n",
    "\n",
    "\n",
    "\n",
    "  # fit function to train the model with dataset\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "    # number of data points in the dataset (number of rows)  -->  m\n",
    "    # number of input features in the dataset (number of columns)  --> n\n",
    "        self.m, self.n = X.shape\n",
    "    #initiating weight & bias value\n",
    "        self.w = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    # implementing Gradient Descent for Optimization\n",
    "        for i in range(self.no_of_iterations):     \n",
    "          self.update_weights()\n",
    "\n",
    "\n",
    "\n",
    "    def update_weights(self):\n",
    "\n",
    "        # Y_hat formula (sigmoid function)\n",
    "        Y_hat = 1 / (1 + np.exp( - (self.X.dot(self.w) + self.b ) ))    \n",
    "        # derivaties\n",
    "        dw = (1/self.m)*np.dot(self.X.T, (Y_hat - self.Y))\n",
    "        db = (1/self.m)*np.sum(Y_hat - self.Y)\n",
    "\n",
    "        # updating the weights & bias using gradient descent\n",
    "        self.w = self.w - self.learning_rate * dw\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "\n",
    "\n",
    "  # Sigmoid Equation & Decision Boundary\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        Y_pred = 1 / (1 + np.exp( - (X.dot(self.w) + self.b ) ))     \n",
    "        Y_pred = np.where( Y_pred > 0.5, 1, 0)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f8f6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cfe44d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc710a",
   "metadata": {},
   "source": [
    "Put all the feauture excluding output columns in X and Output column in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "805035cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('Outcome',axis=1)\n",
    "Y=data['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4ddc4",
   "metadata": {},
   "source": [
    "Standardize all the values used when dataset has combination of very large and very small values it is used to standardize them\n",
    "\n",
    "Fit finds the mean and average which are used later for tranforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7533cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0579e",
   "metadata": {},
   "source": [
    "Split 20% to testing data and 80% to training data \n",
    "\n",
    "Stratify Y means equal distribution according to the outcome \n",
    "\n",
    "Random_state is randomnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a5c4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9438e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Logistic_Regression(learning_rate=0.01, no_of_iterations=1000)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e42d53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7077922077922078\n"
     ]
    }
   ],
   "source": [
    "X_test_prediction = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score( Y_test, X_test_prediction)\n",
    "print(test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "328e837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833876221498371\n"
     ]
    }
   ],
   "source": [
    "# accuracy score on the training data\n",
    "X_train_prediction = classifier.predict(X_train)\n",
    "training_data_accuracy = accuracy_score( Y_train, X_train_prediction)\n",
    "print(training_data_accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61b628a0",
   "metadata": {},
   "source": [
    "changing the input_data to numpy array \n",
    "reshape the array as we are predicting for one data 1 is row and -1 indicates adjust columns according to the need\n",
    "standardize the input data\n",
    "Ino=put data is standardize then it is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57f9b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3429808   1.41167241  0.14964075 -0.09637905  0.82661621 -0.78595734\n",
      "   0.34768723  1.51108316]]\n",
      "[1]\n",
      "The person is diabetic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKSHAM CHAND\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
    "input_data = np.asarray(input_data)\n",
    "input_data= input_data.reshape(1,-1)\n",
    "input_data = scaler.transform(input_data)\n",
    "print(input_data)\n",
    "prediction = classifier.predict(input_data)\n",
    "print(prediction)\n",
    "if (prediction == 0):\n",
    "  print('The person is not diabetic')\n",
    "else:\n",
    "  print('The person is diabetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd0ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
